---
layout: single
title:  "WSL, Docker, Airflow install"
---

# 1. WSL?
## Windows Subsystem for Linux
- Windows에서 리눅스 실행환경을 지원하는 Windows의 확장기능
- Windows에서 바로 리눅스 명령어를 실행할 수 있어서, Windows와 리눅스를 함께 사용하는 개발자들에게 편리
- 리눅스를 왜 사용하냐고 : 가장 큰 이유는 마우스 클릭과 같은 동작으로 수행되는 GUI(Graphical User Interface) 대신 Command Line Interface를 사용해서 명령어 통해 작업수행이 일반적으로 더 빠르고 효율적임. 
- bash : 사용자가 리눅스 명령어를 입력하고 실행할 수 있는 환경을 제공하는 프로그램. 일반적으로 리눅스 시스템에서 사용되는 기본 쉘은 Bash이지만, 다른 쉘도 사용할 수 있다.

## VM
- Virtual Machine : 쉽게 말하면 컴퓨터 안에 구축된 가상컴퓨터 환경(has CPU, Memory, Network Interface and Storage)을 사용했었다.
- 그런데 Overhead 문제(어떤 처리를 하기 위해 들어가는 간접적인 처리 시간 및 메모리)가 심해져서 WSL을 사용해서 오버헤드 문제를 해결

## wsl --install -> wsl -l -v -> wsl
- 기본적으로 Ubuntu가 설치됨 : 가장 범용적인 리눅스 배포판, 사용자 친화적이고 다양한 패키지 및 라이브러리 지원

# 2. Airflow를 다루는데 왜 WSL을 설치?
- Airflow : 대규모 데이터 파이프라인 및 작업스케줄링을 위한 운영환경
- Windows에 Airflow를 직접 설치할 수 없기 때문에 Windows에서 리눅스 작업환경을 만들기 위해 필수
- 여유가 된다면 가상화 VM or Public Cloud의 컴퓨팅 서비스에서 VM 만든다음 그 안에 리눅스 설치해도 되긴 함.

# 3. Linux Commands
> pwd : 현재 디렉토리 경로 출력
> ls -al : 현재 디렉토리 파일 목록 출력 -자세히
> cd : change directory
> mkdir : make directory
> touch : 새로운 파일 생성
> rm : 파일 삭제
> rm -r 폴더명 : r옵션을 주면 디렉토리를 삭제
> cp [copy할파일명] [copy한파일명] : 파일복사
> cp -r [copy할디렉토리명] [copy한디렉토리명] : 디렉토리 복사
> mv [옮길 파일/바꾸고 싶은 기이름] [옮길 디렉토리/새로 지어줄 이름] : 파일 이동/이름 변경
> tar cvf [압축파일의 이름] [압축할대상] : 파일/디렉토리를 압축(cvf)
> tar xvf [압축파일의 이름] : 압축 해제

# 4. Docker & Airflow 설치 
## 1) Docker
  (1) 개념 : 리눅스 내에서 가상화 기술을 활용해 어플리케이션을 독립적인 환경에서 실행시키는 기술
  (2) 가상화 서버(VM)과의 차이 : 기존의 가상화 기술은 Host 서버 위에 Guest OS를 설치하여 여러 개의 VM을 동작시켰다. 하지만 Docker은 이러한 Guest OS를 없애고, App을 독립된 '컨테이너'로 실행해 오버헤드 문제를 최소화
  (3) 컨테이너 : 도커에서 각 애플리케이션을 컨테이너라는 단위로 관리한다. 컨테이너는 격리된 환경에서 App과 그에 필요한 종속성을 실행할 수 있게 한다.
  (4) 장점 : 가상화 서버에 비해 더 빠르고 가벼우며, 여러 개의 컨테이너를 병렬로 실행할 수 있어 리소스를 효율적으로 활용할 수 있다.
  (5) 설치 : wsl에 도커를 설치해야 함. 

## 2) wsl 위에 Docker 설치

    (1) Install Docker Engine on Ubuntu
      - (패키지 목록 업데이트) sudo apt-get update
      - (Docker 설치에 필요한 패키지 설치) sudo apt-get install apt-transport-https ca-certificates curl software-properties-common
      - Docker의 공식 GPG 키 추가 : curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

      - Docker 패키지 저장소 추가 : sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
      - 다시 패키지 목록 업데이트 : sudo apt-get update
      - Docker 설치 : sudo apt-get install docker-ce docker-ce-cli containerd.io
      - 
    (2) 도커 서비스 시작하는 명령어 : sudo service docker start
    (3) sudo docker run hello-world : Docker가 정상적으로 설치됐는지 확인하기 위해 Hellow world 이미지 실행. 이 이미지는 Docker Hub에서 다운로드되어 로컬 시스템에서 실행됨
    (4) 결과 확인 : 이제 도커를 사용해 다른 컨테이너를 실행하거나 이미지를 빌드해서 개발 및 운영 작업을 수행할 준비, 환경설정이 끝났다!
``` bash
      Hello from Docker!
      This message shows that your installation appears to be working correctly.
      
      To generate this message, Docker took the following steps:
       1. The Docker client contacted the Docker daemon.
       2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
          (amd64)
       3. The Docker daemon created a new container from that image which runs the
          executable that produces the output you are currently reading.
       4. The Docker daemon streamed that output to the Docker client, which sent it
          to your terminal.
 ```

## 3) Docker Compose을 이용한 Airflow 설치
    - Airflow를 설치할 수 있는 여러 방법 중 하나로 도커 설치를 이용한다. 도커 컴포즈를 이용하면 한번에 쉽게 설치 가능
    - Docker Compuse : 시스템 구성 시에 필요한 여러 개의 도커 컨테이너 설정을 한번에 관리하기 위한 도커 확장기술로, 에어플로우를 설치하기 위한 도커 컨테이너 세팅 내용이 들어있음.
    (1) airflow docker install
      - Fetching docker-compose.yaml 
      - Initializing Environment
        - Setting the right Airflow user
        - Initialize the database : sudo docker compose up airflow-init
        - Running Airflow : 첫 번째 터미널에서 sudo docker compose up 
    (2) 첫 번째의 프롬프트는 그대로 두고, 두 번째 wsl terminal 열어서 sudo docker ps
      - 출력된 6개의 컨테이너는 Apache Airflow 서비스를 구성하는 여러 구성 요소 : 이들은 모두 함께 작동하여 Airflow 서비스가 원활하게 동작할 수 있도록 지원
        - Airflow trigger : Airflow 트리거는 DAG 실행을 트리거하고 예약된 작업을 실행. 이 컨테이너는 트리거 프로세스를 실행
        - Airflow sheduler : Airflow 스케줄러는 DAG를 기반으로 작업을 예약하고 실행. 이 컨테이너는 스케줄러 프로세스를 실행
        - Airflow worker : Airflow 워커는 DAG에서 정의된 작업을 실행. 여러 워커가 병렬로 작업을 처리할 수 있음
        - Airflow webserver : Airflow 웹 서버는 사용자 인터페이스를 제공하고 DAG 실행 상태를 모니터링. 이 컨테이너는 웹 서버 프로세스를 실행
        - postgres : Airflow는 상태와 메타데이터를 저장하기 위해 PostgreSQL 데이터베이스를 사용. 이 컨테이너는 PostgreSQL 데이터베이스 서버를 실행.
        - redis : Airflow는 작업의 상태와 메시지 브로커로 Redis를 사용. 이 컨테이너는 Redis 서버를 실행
    (3) Airflow 서비스 접속해보기 : localhost:8080 -> 로그인

## 4) Python 가상환경
    - 라이브러리 버전 충돌 방지를 위해 설치 및 사용되는 파이썬 인터프리터 환경을 격리시키는 기술
    - 파이썬은 라이브러리 설치 시점에 따라서도 설치되는 버전이 상이한 경우가 많음.
    - global Python 인터프리터 환경에서 A 프로젝트를 할 때 설치한 C라이브러리 1.0버전, B 프로젝트를 할 때 설치한 C라이브러리 2.0
    - 이 경우 A 프로젝트는 라이브러리의 버전이 달라짐으로써 사용할 수 없게 되는 문제가 발생한다. 이를 종속성 문제가 발생해 충돌했다고 한다.
    - 따라서 파이썬의 가상환경을 통해 A, B 프로젝트를 서로 영향을 주지 않고 격리되어 각자 필요한 라이브러리를 그때그때 설치해서 사용하며 개발
    - 그러니까 파이썬 가상환경은 파이썬 프로젝트를 할 때마다 하나씩 만들어 줘야 함. 
    - Airflow 프로젝트를 위해서 파이썬 가상환경을 설치하자!
